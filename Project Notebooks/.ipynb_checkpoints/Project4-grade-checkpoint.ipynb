{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "In this project, we will practice two major skills: collecting data by scraping a website and then building a binary predictor with Logistic Regression.\n",
    "\n",
    "We are going to collect salary information on data science jobs in a variety of markets. Then using the location, title and summary of the job we will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, we will convert this problem into classification and use Logistic Regression.\n",
    "\n",
    "- Question: Why would we want this to be a classification problem?\n",
    "- Answer: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9732c901-ae26-4160-8376-42e22dd327df"
   },
   "source": [
    "#### Setup a request (using `requests`) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "e915023e-6b0d-4982-af2a-b1e0355f4927"
   },
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "2efefc73-064a-482d-b3b5-ddf5508cb4ec"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning to use Beutifulsoup to extract information out of indeed.com"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "2c6752c4-7704-4c94-8bc0-6f13d2d0d570"
   },
   "source": [
    "\n",
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.content)\n",
    "results = soup.find_all(\"div\", {'class' : ' row result'})\n",
    "print results[0].find('span', {'class':'company'}).get_text().strip()\n",
    "print results[0].find('a', {'class':'turnstileLink'}).get_text().strip()\n",
    "print results[0].find('span', {'class':'location'}).get_text().strip()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "These links helped me determine the behavior of the website in order loop through several results (Pages, cities and salary)\n",
    "\n",
    "http://www.indeed.com/jobs?q=data+scientist+%2450%2C000&l=New+York%2C+NY\n",
    "http://www.indeed.com/jobs?q=data+scientist+%2450%2C000&l=San+Francisco%2C+CA\n",
    "http://www.indeed.com/jobs?q=data+scientist+%2470%2C000&l=San+Francisco%2C+CA\n",
    "http://www.indeed.com/jobs?q=data+scientist+%24100%2C000&l=San+Francisco%2C+CA\n",
    "http://www.indeed.com/jobs?q=data+scientist+%2450%2C000+-+%2490%2C000&l=San+Francisco%2C+CA\n",
    "http://www.indeed.com/jobs?q=data+scientist+%2450%2C000+-+%2490%2C000&l=San+Francisco%2C+CA&start=10\n",
    "http://www.indeed.com/jobs?q=data+scientist+%2450%2C000+-+%2490%2C000&l=San+Francisco%2C+CA&start=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "bb0b866a-26a7-45e9-8084-5a0f90eb4b3e"
   },
   "source": [
    "Let's look at one result more closely. A single `result` looks like\n",
    "\n",
    "```\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=2480d203f7e97210&amp;jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```\n",
    "\n",
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is available in a `nobr` element inside of a `td` element with `class='snip`.\n",
    "- The title of a job is in a link with class set to `jobtitle` and a `data-tn-element=\"jobTitle`.  \n",
    "- The location is set in a `span` with `class='location'`. \n",
    "- The company is set in a `span` with `class='company'`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "f1eddb90-4ba8-483c-a229-77e93aa53119"
   },
   "source": [
    "#### Obtaining results for low salary range\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "a1af53c9-9090-494f-b82e-cadb60a54909"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary Index</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alambic Investment Management, LP</td>\n",
       "      <td>Data Scientist / Engineer</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>We are a small, entrepreneurial San Francisco-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitch</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>We think of Emmett, the CEO, as Twitchâ€™s origi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stemcentrx</td>\n",
       "      <td>Senior Scientist I/II/III - Small Molecule Mas...</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Experience working with various MS data proces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samba TV</td>\n",
       "      <td>Research Scientist, Video and Image Processing</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Solid foundation in computer science, with str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ancestry</td>\n",
       "      <td>Scientific Data Wrangler</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Working with a nimble team of physicians, gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trulia</td>\n",
       "      <td>Quantitative Analyst</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Experience with Big Data tools such as Hive/Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thermo Fisher Scientific</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BS in computer science MS in computer science ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DiscoveRx Corporation</td>\n",
       "      <td>Scientist/Senior Scientist</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Scientist/Senior Scientist position currently ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Natera</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Natera is seeking a highly motivated Data Scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Metabiota</td>\n",
       "      <td>Scientific Marketing Intern</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Interact with scientists at Metabiotaâ€™s DC, SF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>University of California Berkeley</td>\n",
       "      <td>Associate Director of Data Analysis, Haas Scho...</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Experienced in working with a small to med siz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Walmart eCommerce</td>\n",
       "      <td>Research and Analytics</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The team will consist of other behavioral scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PR Hacker</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>If so, you might make a killer Data Scientist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fanatics Inc.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ability to use SQL to perform data analysis. A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Genentech</td>\n",
       "      <td>Scientific Researcher/ Senior Scientific Resea...</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The position will report to a lead Scientist f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Colliers International | Oakland</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Compile statistical data specific to client or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Illumina, Inc.</td>\n",
       "      <td>Research Associate- Scientist</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Strong bioinformatics, data analysis and visua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Realogy Corporate</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Junior Data Scientist. The Junior Data Scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>University of California San Francisco</td>\n",
       "      <td>Bioinformatics Programmer</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Superior computer skills in data management an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>University of California San Francisco</td>\n",
       "      <td>Research Data Analyst</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Research Data Analyst will provide statist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Fanatics Inc.</td>\n",
       "      <td>MTS 1, Data Scientist</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ability to use SQL to perform data analysis. A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Payette Group</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Having tens of thousands of debtors and contac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Omada Health</td>\n",
       "      <td>User Insights Researcher, Product</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Digging into the whys behind patterns in our d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Nuna</td>\n",
       "      <td>Commercial Health Data Analyst</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Works with consultants, analysts and data scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SF VA Medical Center</td>\n",
       "      <td>Statistician, Sr.</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Experience with data cleaning and data quality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Lyft Corporate</td>\n",
       "      <td>Research &amp; Insights Analyst</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>In-person, web, mobile, secondary market resea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>University of California San Francisco</td>\n",
       "      <td>Sr. Statistician</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>And will supervise and work with the data mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MakroScientific</td>\n",
       "      <td>Research Associate</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Biological image data analysis, using microsco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>Bioinformatic Analyst</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Working with a nimble team of physicians, gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>University of California Berkeley</td>\n",
       "      <td>Research and Policy Analyst</td>\n",
       "      <td>San+Francisco%2C+CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Collect and analyze workforce data, including ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>Magic Leap, Inc.</td>\n",
       "      <td>Accounting Manager (TX)</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ability to define problems, collect data, esta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>Natera</td>\n",
       "      <td>Laboratory Director</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2 or more yearsâ€™ experience in a CLIA-certifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>University of Texas at Austin</td>\n",
       "      <td>Engineering Scientist Associate - Software Def...</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Experience with digital data distribution tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>Myriad Genetics, Inc.</td>\n",
       "      <td>Temporary Laboratory Technician (Testing)</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Lab Technician I reports to a Supervisor, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>Natera</td>\n",
       "      <td>Customer Care Tier 1 Specialist</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Data collection and maintenance. The Natera te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>Evins Personnel Consultants, Inc.</td>\n",
       "      <td>Medical and Clinical Laboratory</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Log data from tests, discuss results and findi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>Magic Leap, Inc.</td>\n",
       "      <td>Accounting Manager (TX)</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ability to define problems, collect data, esta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>Natera</td>\n",
       "      <td>Laboratory Director</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2 or more yearsâ€™ experience in a CLIA-certifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>University of Texas at Austin</td>\n",
       "      <td>Engineering Scientist Associate - Software Def...</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Experience with digital data distribution tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>Myriad Genetics, Inc.</td>\n",
       "      <td>Temporary Laboratory Technician (Testing)</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Lab Technician I reports to a Supervisor, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>Natera</td>\n",
       "      <td>Customer Care Tier 1 Specialist</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Data collection and maintenance. The Natera te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>Evins Personnel Consultants, Inc.</td>\n",
       "      <td>Medical and Clinical Laboratory</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Log data from tests, discuss results and findi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>Magic Leap, Inc.</td>\n",
       "      <td>Accounting Manager (TX)</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ability to define problems, collect data, esta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>Natera</td>\n",
       "      <td>Laboratory Director</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2 or more yearsâ€™ experience in a CLIA-certifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>University of Texas at Austin</td>\n",
       "      <td>Engineering Scientist Associate - Software Def...</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Experience with digital data distribution tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>Myriad Genetics, Inc.</td>\n",
       "      <td>Temporary Laboratory Technician (Testing)</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Lab Technician I reports to a Supervisor, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>Natera</td>\n",
       "      <td>Customer Care Tier 1 Specialist</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Data collection and maintenance. The Natera te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>Evins Personnel Consultants, Inc.</td>\n",
       "      <td>Medical and Clinical Laboratory</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Log data from tests, discuss results and findi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>Magic Leap, Inc.</td>\n",
       "      <td>Accounting Manager (TX)</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ability to define problems, collect data, esta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>Natera</td>\n",
       "      <td>Laboratory Director</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2 or more yearsâ€™ experience in a CLIA-certifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>University of Texas at Austin</td>\n",
       "      <td>Engineering Scientist Associate - Software Def...</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Experience with digital data distribution tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>Myriad Genetics, Inc.</td>\n",
       "      <td>Temporary Laboratory Technician (Testing)</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Lab Technician I reports to a Supervisor, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>Natera</td>\n",
       "      <td>Customer Care Tier 1 Specialist</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Data collection and maintenance. The Natera te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>Evins Personnel Consultants, Inc.</td>\n",
       "      <td>Medical and Clinical Laboratory</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Log data from tests, discuss results and findi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>Magic Leap, Inc.</td>\n",
       "      <td>Accounting Manager (TX)</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ability to define problems, collect data, esta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>Natera</td>\n",
       "      <td>Laboratory Director</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2 or more yearsâ€™ experience in a CLIA-certifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>University of Texas at Austin</td>\n",
       "      <td>Engineering Scientist Associate - Software Def...</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Experience with digital data distribution tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>Myriad Genetics, Inc.</td>\n",
       "      <td>Temporary Laboratory Technician (Testing)</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Lab Technician I reports to a Supervisor, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>Natera</td>\n",
       "      <td>Customer Care Tier 1 Specialist</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Data collection and maintenance. The Natera te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>Evins Personnel Consultants, Inc.</td>\n",
       "      <td>Medical and Clinical Laboratory</td>\n",
       "      <td>Austin%2C+TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Log data from tests, discuss results and findi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>854 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Company Name  \\\n",
       "0         Alambic Investment Management, LP   \n",
       "1                                    Twitch   \n",
       "2                                Stemcentrx   \n",
       "3                                  Samba TV   \n",
       "4                                  Ancestry   \n",
       "5                                    Trulia   \n",
       "6                  Thermo Fisher Scientific   \n",
       "7                     DiscoveRx Corporation   \n",
       "8                                    Natera   \n",
       "9                                 Metabiota   \n",
       "10        University of California Berkeley   \n",
       "11                        Walmart eCommerce   \n",
       "12                                PR Hacker   \n",
       "13                            Fanatics Inc.   \n",
       "14                                Genentech   \n",
       "15         Colliers International | Oakland   \n",
       "16                           Illumina, Inc.   \n",
       "17                        Realogy Corporate   \n",
       "18   University of California San Francisco   \n",
       "19   University of California San Francisco   \n",
       "20                            Fanatics Inc.   \n",
       "21                            Payette Group   \n",
       "22                             Omada Health   \n",
       "23                                     Nuna   \n",
       "24                     SF VA Medical Center   \n",
       "25                           Lyft Corporate   \n",
       "26   University of California San Francisco   \n",
       "27                          MakroScientific   \n",
       "28                              AncestryDNA   \n",
       "29        University of California Berkeley   \n",
       "..                                      ...   \n",
       "824                        Magic Leap, Inc.   \n",
       "825                                  Natera   \n",
       "826           University of Texas at Austin   \n",
       "827                   Myriad Genetics, Inc.   \n",
       "828                                  Natera   \n",
       "829       Evins Personnel Consultants, Inc.   \n",
       "830                        Magic Leap, Inc.   \n",
       "831                                  Natera   \n",
       "832           University of Texas at Austin   \n",
       "833                   Myriad Genetics, Inc.   \n",
       "834                                  Natera   \n",
       "835       Evins Personnel Consultants, Inc.   \n",
       "836                        Magic Leap, Inc.   \n",
       "837                                  Natera   \n",
       "838           University of Texas at Austin   \n",
       "839                   Myriad Genetics, Inc.   \n",
       "840                                  Natera   \n",
       "841       Evins Personnel Consultants, Inc.   \n",
       "842                        Magic Leap, Inc.   \n",
       "843                                  Natera   \n",
       "844           University of Texas at Austin   \n",
       "845                   Myriad Genetics, Inc.   \n",
       "846                                  Natera   \n",
       "847       Evins Personnel Consultants, Inc.   \n",
       "848                        Magic Leap, Inc.   \n",
       "849                                  Natera   \n",
       "850           University of Texas at Austin   \n",
       "851                   Myriad Genetics, Inc.   \n",
       "852                                  Natera   \n",
       "853       Evins Personnel Consultants, Inc.   \n",
       "\n",
       "                                             Job Title             Location  \\\n",
       "0                            Data Scientist / Engineer  San+Francisco%2C+CA   \n",
       "1                                       Data Scientist  San+Francisco%2C+CA   \n",
       "2    Senior Scientist I/II/III - Small Molecule Mas...  San+Francisco%2C+CA   \n",
       "3       Research Scientist, Video and Image Processing  San+Francisco%2C+CA   \n",
       "4                             Scientific Data Wrangler  San+Francisco%2C+CA   \n",
       "5                                 Quantitative Analyst  San+Francisco%2C+CA   \n",
       "6                                       Data Scientist  San+Francisco%2C+CA   \n",
       "7                           Scientist/Senior Scientist  San+Francisco%2C+CA   \n",
       "8                                       Data Scientist  San+Francisco%2C+CA   \n",
       "9                          Scientific Marketing Intern  San+Francisco%2C+CA   \n",
       "10   Associate Director of Data Analysis, Haas Scho...  San+Francisco%2C+CA   \n",
       "11                              Research and Analytics  San+Francisco%2C+CA   \n",
       "12                                      Data Scientist  San+Francisco%2C+CA   \n",
       "13                                      Data Scientist  San+Francisco%2C+CA   \n",
       "14   Scientific Researcher/ Senior Scientific Resea...  San+Francisco%2C+CA   \n",
       "15                                    Research Analyst  San+Francisco%2C+CA   \n",
       "16                       Research Associate- Scientist  San+Francisco%2C+CA   \n",
       "17                               Junior Data Scientist  San+Francisco%2C+CA   \n",
       "18                           Bioinformatics Programmer  San+Francisco%2C+CA   \n",
       "19                               Research Data Analyst  San+Francisco%2C+CA   \n",
       "20                               MTS 1, Data Scientist  San+Francisco%2C+CA   \n",
       "21                                      Data Scientist  San+Francisco%2C+CA   \n",
       "22                   User Insights Researcher, Product  San+Francisco%2C+CA   \n",
       "23                      Commercial Health Data Analyst  San+Francisco%2C+CA   \n",
       "24                                   Statistician, Sr.  San+Francisco%2C+CA   \n",
       "25                         Research & Insights Analyst  San+Francisco%2C+CA   \n",
       "26                                    Sr. Statistician  San+Francisco%2C+CA   \n",
       "27                                  Research Associate  San+Francisco%2C+CA   \n",
       "28                               Bioinformatic Analyst  San+Francisco%2C+CA   \n",
       "29                         Research and Policy Analyst  San+Francisco%2C+CA   \n",
       "..                                                 ...                  ...   \n",
       "824                            Accounting Manager (TX)         Austin%2C+TX   \n",
       "825                                Laboratory Director         Austin%2C+TX   \n",
       "826  Engineering Scientist Associate - Software Def...         Austin%2C+TX   \n",
       "827          Temporary Laboratory Technician (Testing)         Austin%2C+TX   \n",
       "828                    Customer Care Tier 1 Specialist         Austin%2C+TX   \n",
       "829                    Medical and Clinical Laboratory         Austin%2C+TX   \n",
       "830                            Accounting Manager (TX)         Austin%2C+TX   \n",
       "831                                Laboratory Director         Austin%2C+TX   \n",
       "832  Engineering Scientist Associate - Software Def...         Austin%2C+TX   \n",
       "833          Temporary Laboratory Technician (Testing)         Austin%2C+TX   \n",
       "834                    Customer Care Tier 1 Specialist         Austin%2C+TX   \n",
       "835                    Medical and Clinical Laboratory         Austin%2C+TX   \n",
       "836                            Accounting Manager (TX)         Austin%2C+TX   \n",
       "837                                Laboratory Director         Austin%2C+TX   \n",
       "838  Engineering Scientist Associate - Software Def...         Austin%2C+TX   \n",
       "839          Temporary Laboratory Technician (Testing)         Austin%2C+TX   \n",
       "840                    Customer Care Tier 1 Specialist         Austin%2C+TX   \n",
       "841                    Medical and Clinical Laboratory         Austin%2C+TX   \n",
       "842                            Accounting Manager (TX)         Austin%2C+TX   \n",
       "843                                Laboratory Director         Austin%2C+TX   \n",
       "844  Engineering Scientist Associate - Software Def...         Austin%2C+TX   \n",
       "845          Temporary Laboratory Technician (Testing)         Austin%2C+TX   \n",
       "846                    Customer Care Tier 1 Specialist         Austin%2C+TX   \n",
       "847                    Medical and Clinical Laboratory         Austin%2C+TX   \n",
       "848                            Accounting Manager (TX)         Austin%2C+TX   \n",
       "849                                Laboratory Director         Austin%2C+TX   \n",
       "850  Engineering Scientist Associate - Software Def...         Austin%2C+TX   \n",
       "851          Temporary Laboratory Technician (Testing)         Austin%2C+TX   \n",
       "852                    Customer Care Tier 1 Specialist         Austin%2C+TX   \n",
       "853                    Medical and Clinical Laboratory         Austin%2C+TX   \n",
       "\n",
       "     Salary Index                                            Summary  \n",
       "0             0.0  We are a small, entrepreneurial San Francisco-...  \n",
       "1             0.0  We think of Emmett, the CEO, as Twitchâ€™s origi...  \n",
       "2             0.0  Experience working with various MS data proces...  \n",
       "3             0.0  Solid foundation in computer science, with str...  \n",
       "4             0.0  Working with a nimble team of physicians, gene...  \n",
       "5             0.0  Experience with Big Data tools such as Hive/Pr...  \n",
       "6             0.0  BS in computer science MS in computer science ...  \n",
       "7             0.0  Scientist/Senior Scientist position currently ...  \n",
       "8             0.0  Natera is seeking a highly motivated Data Scie...  \n",
       "9             0.0  Interact with scientists at Metabiotaâ€™s DC, SF...  \n",
       "10            0.0  Experienced in working with a small to med siz...  \n",
       "11            0.0  The team will consist of other behavioral scie...  \n",
       "12            0.0  If so, you might make a killer Data Scientist ...  \n",
       "13            0.0  Ability to use SQL to perform data analysis. A...  \n",
       "14            0.0  The position will report to a lead Scientist f...  \n",
       "15            0.0  Compile statistical data specific to client or...  \n",
       "16            0.0  Strong bioinformatics, data analysis and visua...  \n",
       "17            0.0  Junior Data Scientist. The Junior Data Scienti...  \n",
       "18            0.0  Superior computer skills in data management an...  \n",
       "19            0.0  The Research Data Analyst will provide statist...  \n",
       "20            0.0  Ability to use SQL to perform data analysis. A...  \n",
       "21            0.0  Having tens of thousands of debtors and contac...  \n",
       "22            0.0  Digging into the whys behind patterns in our d...  \n",
       "23            0.0  Works with consultants, analysts and data scie...  \n",
       "24            0.0  Experience with data cleaning and data quality...  \n",
       "25            0.0  In-person, web, mobile, secondary market resea...  \n",
       "26            0.0  And will supervise and work with the data mana...  \n",
       "27            0.0  Biological image data analysis, using microsco...  \n",
       "28            0.0  Working with a nimble team of physicians, gene...  \n",
       "29            0.0  Collect and analyze workforce data, including ...  \n",
       "..            ...                                                ...  \n",
       "824           0.0  Ability to define problems, collect data, esta...  \n",
       "825           0.0  2 or more yearsâ€™ experience in a CLIA-certifie...  \n",
       "826           0.0  Experience with digital data distribution tech...  \n",
       "827           0.0  The Lab Technician I reports to a Supervisor, ...  \n",
       "828           0.0  Data collection and maintenance. The Natera te...  \n",
       "829           0.0  Log data from tests, discuss results and findi...  \n",
       "830           0.0  Ability to define problems, collect data, esta...  \n",
       "831           0.0  2 or more yearsâ€™ experience in a CLIA-certifie...  \n",
       "832           0.0  Experience with digital data distribution tech...  \n",
       "833           0.0  The Lab Technician I reports to a Supervisor, ...  \n",
       "834           0.0  Data collection and maintenance. The Natera te...  \n",
       "835           0.0  Log data from tests, discuss results and findi...  \n",
       "836           0.0  Ability to define problems, collect data, esta...  \n",
       "837           0.0  2 or more yearsâ€™ experience in a CLIA-certifie...  \n",
       "838           0.0  Experience with digital data distribution tech...  \n",
       "839           0.0  The Lab Technician I reports to a Supervisor, ...  \n",
       "840           0.0  Data collection and maintenance. The Natera te...  \n",
       "841           0.0  Log data from tests, discuss results and findi...  \n",
       "842           0.0  Ability to define problems, collect data, esta...  \n",
       "843           0.0  2 or more yearsâ€™ experience in a CLIA-certifie...  \n",
       "844           0.0  Experience with digital data distribution tech...  \n",
       "845           0.0  The Lab Technician I reports to a Supervisor, ...  \n",
       "846           0.0  Data collection and maintenance. The Natera te...  \n",
       "847           0.0  Log data from tests, discuss results and findi...  \n",
       "848           0.0  Ability to define problems, collect data, esta...  \n",
       "849           0.0  2 or more yearsâ€™ experience in a CLIA-certifie...  \n",
       "850           0.0  Experience with digital data distribution tech...  \n",
       "851           0.0  The Lab Technician I reports to a Supervisor, ...  \n",
       "852           0.0  Data collection and maintenance. The Natera te...  \n",
       "853           0.0  Log data from tests, discuss results and findi...  \n",
       "\n",
       "[854 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "base_url = \"http://www.indeed.com/jobs?q=data+scientist+%2430%2C000+-+%2480%2C000&l=\"\n",
    "\n",
    "start_from = '&start='    # start page number\n",
    "\n",
    "\n",
    "df = pd.DataFrame()   # create a new data frame\n",
    "\n",
    "for city in set(['New+York%2C+NY', 'Chicago%2C+IL', 'San+Francisco%2C+CA', \n",
    "                                        'Austin%2C+TX', 'Boston%2C+MA']):\n",
    "    cityString = city\n",
    "    for page in range(1,21): # Page from 1 to 20 \n",
    "        page = (page-1) * 10  #Page Equation\n",
    "        url = \"%s%s%s%d\" % (base_url, cityString , start_from, page) # get full url \n",
    "        r = requests.get(url) #\n",
    "        soup = BeautifulSoup(r.content,'lxml') \n",
    "\n",
    "        results = soup.find_all(\"div\", {'class' : ' row result'}) # we're interested in each row\n",
    "    \n",
    "        # trying to get each specific job information (such as company name, job title, ...)\n",
    "        for i in range(len(results)): \n",
    "            comp_name = results[i].find('span', {'class':'company'}).get_text().strip()\n",
    "            job_title = results[i].find('a', {'class':'turnstileLink'}).get_text().strip()\n",
    "            location = city\n",
    "            summary = results[i].find('span',{'class':'summary'}).get_text().strip()\n",
    "            \n",
    "\n",
    "    \n",
    "            # Add job info to our data frame\n",
    "            df = df.append({'Company Name': comp_name, 'Job Title': job_title, \n",
    "                        'Location': location, 'Summary': summary, \n",
    "                            'Salary Index': int(0)}, ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "e8beed7c-3e42-40c0-810f-5f67f8f885a0"
   },
   "source": [
    "#### Obtaining results for high salary range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "a9aa87ec-3575-4a01-a986-eb684f2c47d0"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-483ce095b6af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m  \u001b[0;31m#Page Equation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s%s%s%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcityString\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mstart_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get full url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jb3/anaconda/lib/python2.7/site-packages/requests/api.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jb3/anaconda/lib/python2.7/site-packages/requests/api.pyc\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jb3/anaconda/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    466\u001b[0m         }\n\u001b[1;32m    467\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jb3/anaconda/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# Resolve redirects if allowed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_redirects\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# Shuffle things around if there's history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jb3/anaconda/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36mresolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0madapter_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             )\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jb3/anaconda/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jb3/anaconda/lib/python2.7/site-packages/requests/models.pyc\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    735\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jb3/anaconda/lib/python2.7/site-packages/requests/models.pyc\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jb3/anaconda/lib/python2.7/site-packages/requests/packages/urllib3/response.pyc\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jb3/anaconda/lib/python2.7/site-packages/requests/packages/urllib3/response.pyc\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jb3/anaconda/lib/python2.7/site-packages/requests/packages/urllib3/response.pyc\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jb3/anaconda/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_url = \"http://www.indeed.com/jobs?q=data+scientist+%2480%2C000+-+%2530%2C000&l=\"\n",
    "\n",
    "start_from = '&start='    # start page number\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame()   # create a new data frame\n",
    "\n",
    "for city in set(['New+York%2C+NY', 'Chicago%2C+IL', 'San+Francisco%2C+CA', \n",
    "                                        'Austin%2C+TX', 'Boston%2C+MA']):\n",
    "    cityString = city\n",
    "    for page in range(1,21): # Page from 1 to 20 \n",
    "        page = (page-1) * 10  #Page Equation\n",
    "        url = \"%s%s%s%d\" % (base_url, cityString , start_from, page) # get full url \n",
    "        r = requests.get(url) #\n",
    "        soup = BeautifulSoup(r.content,'lxml') \n",
    "\n",
    "        results = soup.find_all(\"div\", {'class' : ' row result'}) # we're interested in each row\n",
    "    \n",
    "        # trying to get each specific job information (such as company name, job title, ...)\n",
    "        for i in range(len(results)): \n",
    "            comp_name = results[i].find('span', {'class':'company'}).get_text().strip()\n",
    "            job_title = results[i].find('a', {'class':'turnstileLink'}).get_text().strip()\n",
    "            location = city\n",
    "            summary = results[i].find('span',{'class':'summary'}).get_text().strip()\n",
    "            \n",
    "\n",
    "    \n",
    "            # Add job info to our data frame\n",
    "            df2 = df2.append({'Company Name': comp_name, 'Job Title': job_title, \n",
    "                        'Location': location, 'Summary': summary, \n",
    "                            'Salary Index': int(1)}, ignore_index=True)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning about the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "04b0f9af-540e-402f-8292-81748707c676"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>854</td>\n",
       "      <td>854</td>\n",
       "      <td>854</td>\n",
       "      <td>854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>498</td>\n",
       "      <td>613</td>\n",
       "      <td>5</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Natera</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Boston%2C+MA</td>\n",
       "      <td>Log data from tests, discuss results and findi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>180</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Company Name         Job Title      Location  \\\n",
       "count           854               854           854   \n",
       "unique          498               613             5   \n",
       "top          Natera  Research Analyst  Boston%2C+MA   \n",
       "freq             37                40           180   \n",
       "\n",
       "                                                  Summary  \n",
       "count                                                 854  \n",
       "unique                                                721  \n",
       "top     Log data from tests, discuss results and findi...  \n",
       "freq                                                   14  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = df.dtypes[df.dtypes == \"object\"].index\n",
    "df[categorical].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "6e259594-1c52-436b-ab9e-527e071941c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>436</td>\n",
       "      <td>436</td>\n",
       "      <td>436</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>76</td>\n",
       "      <td>129</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Talon</td>\n",
       "      <td>Dynamics GP Accounting Manager - Chicago, Illi...</td>\n",
       "      <td>New+York%2C+NY</td>\n",
       "      <td>For over 30 years, we have served both clients...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>55</td>\n",
       "      <td>19</td>\n",
       "      <td>180</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Company Name                                          Job Title  \\\n",
       "count           436                                                436   \n",
       "unique           76                                                129   \n",
       "top           Talon  Dynamics GP Accounting Manager - Chicago, Illi...   \n",
       "freq             55                                                 19   \n",
       "\n",
       "              Location                                            Summary  \n",
       "count              436                                                436  \n",
       "unique               4                                                121  \n",
       "top     New+York%2C+NY  For over 30 years, we have served both clients...  \n",
       "freq               180                                                 20  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = df2.dtypes[df.dtypes == \"object\"].index\n",
    "df2[categorical].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "#### Merging the two dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "58533e57-f86b-494a-b841-e7b59c6229c6"
   },
   "outputs": [],
   "source": [
    "mergedDF = [df, df2]\n",
    "df4 = pd.concat(mergedDF)\n",
    "df4 = df4.reset_index()\n",
    "del df4['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "df4.to_csv(\"datascience.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped salaries, create dummy variables for the cities and perform a train test split on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": [
    "df4 = pd.read_csv(\"../Assets/Project4/datascience.csv\")\n",
    "df5=df4[['Location','Salary Index']]\n",
    "dummies = pd.get_dummies( df5[\"Location\"], prefix = \"Location\" )\n",
    "dummies['Intercept']=1\n",
    "dummies.columns=['Austin','Boston', 'Chicago','New York','San Francisco','Intercept']\n",
    "y=df5['Salary Index']\n",
    "X=dummies[['Boston','Chicago','New York','San Francisco','Intercept']]\n",
    "# split data randomly into datasets, 70% train, 30% test using test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=30)\n",
    "\n",
    "#JB need a little more explanation and what you're doing.\n",
    "# You're creating dummies for the cities? Which one do you plan on dropping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Logistic Regression model to predict High/Low salary using statsmodel. Start by ONLY using the location as a feature. Display the coefficients and write a short summary of what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.644395\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>Salary Index</td>   <th>  No. Observations:  </th>  <td>   933</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   928</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Fri, 01 Jul 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.03073</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>10:55:52</td>     <th>  Log-Likelihood:    </th> <td> -601.22</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -620.28</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.057e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Boston</th>        <td>    0.0009</td> <td>    0.217</td> <td>    0.004</td> <td> 0.997</td> <td>   -0.424     0.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chicago</th>       <td>   -0.6417</td> <td>    0.236</td> <td>   -2.716</td> <td> 0.007</td> <td>   -1.105    -0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>New York</th>      <td>   -0.1917</td> <td>    0.221</td> <td>   -0.868</td> <td> 0.385</td> <td>   -0.624     0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>San Francisco</th> <td>   -1.2042</td> <td>    0.262</td> <td>   -4.603</td> <td> 0.000</td> <td>   -1.717    -0.691</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>   -0.1355</td> <td>    0.174</td> <td>   -0.780</td> <td> 0.436</td> <td>   -0.476     0.205</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:           Salary Index   No. Observations:                  933\n",
       "Model:                          Logit   Df Residuals:                      928\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Fri, 01 Jul 2016   Pseudo R-squ.:                 0.03073\n",
       "Time:                        10:55:52   Log-Likelihood:                -601.22\n",
       "converged:                       True   LL-Null:                       -620.28\n",
       "                                        LLR p-value:                 1.057e-07\n",
       "=================================================================================\n",
       "                    coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "---------------------------------------------------------------------------------\n",
       "Boston            0.0009      0.217      0.004      0.997        -0.424     0.426\n",
       "Chicago          -0.6417      0.236     -2.716      0.007        -1.105    -0.179\n",
       "New York         -0.1917      0.221     -0.868      0.385        -0.624     0.241\n",
       "San Francisco    -1.2042      0.262     -4.603      0.000        -1.717    -0.691\n",
       "Intercept        -0.1355      0.174     -0.780      0.436        -0.476     0.205\n",
       "=================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = sm.Logit(y_train, X_train)\n",
    "result = logit.fit()\n",
    "result.summary()\n",
    "\n",
    "#JB what does this mean? what's the intercept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Boston           1.000889\n",
       "Chicago          0.526405\n",
       "New York         0.825581\n",
       "San Francisco    0.299923\n",
       "Intercept        0.873239\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(result.params) #convert your parameters to odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "      <th>OR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Boston</th>\n",
       "      <td>0.654124</td>\n",
       "      <td>1.531481</td>\n",
       "      <td>1.000889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chicago</th>\n",
       "      <td>0.331291</td>\n",
       "      <td>0.836431</td>\n",
       "      <td>0.526405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>0.535650</td>\n",
       "      <td>1.272444</td>\n",
       "      <td>0.825581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Francisco</th>\n",
       "      <td>0.179600</td>\n",
       "      <td>0.500858</td>\n",
       "      <td>0.299923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>0.621122</td>\n",
       "      <td>1.227692</td>\n",
       "      <td>0.873239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   2.5%     97.5%        OR\n",
       "Boston         0.654124  1.531481  1.000889\n",
       "Chicago        0.331291  0.836431  0.526405\n",
       "New York       0.535650  1.272444  0.825581\n",
       "San Francisco  0.179600  0.500858  0.299923\n",
       "Intercept      0.621122  1.227692  0.873239"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf=result.conf_int()\n",
    "conf['OR']=result.params\n",
    "conf.columns=['2.5%','97.5%','OR']\n",
    "np.exp(conf)#convert to odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jb3/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/jb3/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "dfTest=X_test\n",
    "dfTest['predictedSalary'] = result.predict( dfTest )\n",
    "dfTest[\"actualSalary\"] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This loop helped me determine the best cutoff point for my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jb3/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My cutoff is: 0.45 and ACC: 0.55361596009975067\n",
      "My cutoff is: 0.46 and ACC: 0.55361596009975067\n",
      "My cutoff is: 0.47 and ACC: 0.6059850374064838\n",
      "My cutoff is: 0.48 and ACC: 0.6059850374064838\n",
      "My cutoff is: 0.49 and ACC: 0.6059850374064838\n",
      "My cutoff is: 0.5 and ACC: 0.6059850374064838\n",
      "My cutoff is: 0.51 and ACC: 0.6059850374064838\n",
      "My cutoff is: 0.52 and ACC: 0.6059850374064838\n",
      "My cutoff is: 0.53 and ACC: 0.6059850374064838\n",
      "My cutoff is: 0.54 and ACC: 0.6059850374064838\n",
      "My cutoff is: 0.55 and ACC: 0.6059850374064838\n"
     ]
    }
   ],
   "source": [
    "for i in range(45,56,1):\n",
    "    cutoff=i/100.0\n",
    "    xyz = dfTest[\"predictedSalary\"]\n",
    "    dfTest[\"Predicted\"] = [0 if i < cutoff else 1 for i in xyz]\n",
    "    A= confusion_matrix(dfTest['actualSalary'],dfTest['Predicted'])\n",
    "    Accuracy = (A[0,0]+ A[1,1])/float(len(dfTest[\"Predicted\"]))\n",
    "    print \"My cutoff is: %r and ACC: %r\"%(cutoff,Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the information from the previous step, a cutoff of 0.46 is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#JB wwhy, when .47 gives you more ACC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    0   1\n",
      "Actual            \n",
      "0.0        151  92\n",
      "1.0         87  71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jb3/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "cutoff=0.46\n",
    "xyz = dfTest[\"predictedSalary\"]\n",
    "dfTest[\"Predicted\"] = [0 if i < cutoff else 1 for i in xyz]\n",
    "print pd.crosstab(dfTest['actualSalary'], dfTest['Predicted'], rownames=['Actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5536159600997507"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy = (222)/float(len(dfTest[\"Predicted\"]))\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model is around 55% which is a very low number to work with. I believe that there is a lot of Bias in the data collected. I belive that a more reliable source of data should be found. I will continue to use this data set to see if it is possible to increase the accuracy of the model using other tools available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9c9274ef-c9f5-4d56-b286-ecc8709eff9f"
   },
   "source": [
    "#### Rebuild this model with scikit-learn.\n",
    "- You can either create the dummy features manually or use the `dmatrix` function from `patsy`\n",
    "- Remember to scale the feature variables as well!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b76f65cd-cd3a-4e91-af55-12880be7b057"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=30)\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jb3/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/jb3/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "dfTest2=X_test\n",
    "dfTest2['predictedSalary'] = model2.predict(X_test)\n",
    "dfTest2[\"actualSalary\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.605985037406\n",
      "predictedSalary  0.0\n",
      "Actual              \n",
      "0.0              243\n",
      "1.0              158\n"
     ]
    }
   ],
   "source": [
    "print metrics.accuracy_score(y_test, dfTest2['predictedSalary'])\n",
    "print pd.crosstab(y_test, dfTest2['predictedSalary'], rownames=['Actual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly using sklearn logistic regression does improve my accuracy but the model is wrong as it is just predicting everything to be low salary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6119403   0.6119403   0.6119403   0.17910448  0.61654135  0.61654135\n",
      "  0.61654135  0.38345865  0.37593985  0.61654135]\n",
      "0.524048928291\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=10)\n",
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "8c22664b-92e4-4fc2-b7ac-fbac865845d3"
   },
   "source": [
    "#### Compare L1 and L2 regularization for this logistic regression model. What effect does this have on the coefficients learned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "172fd952-5012-4630-81f4-1206da6eb820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.605985037406\n",
      "predictedSalary  0.0\n",
      "Actual              \n",
      "0.0              243\n",
      "1.0              158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jb3/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jb3/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=30)\n",
    "L1Model= LogisticRegression(penalty='l1')\n",
    "L1Model.fit(X_train, y_train)\n",
    "dfTest3=X_test\n",
    "dfTest3['predictedSalary'] = L1Model.predict(X_test)\n",
    "dfTest3[\"actualSalary\"] = y_test\n",
    "print metrics.accuracy_score(y_test, dfTest3['predictedSalary'])\n",
    "print pd.crosstab(y_test, dfTest3['predictedSalary'], rownames=['Actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "56cc8854-d722-411d-a6c7-e86310710f67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.605985037406\n",
      "predictedSalary  0.0\n",
      "Actual              \n",
      "0.0              243\n",
      "1.0              158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jb3/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jb3/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=30)\n",
    "L2Model= LogisticRegression(penalty='l2')\n",
    "L2Model.fit(X_train, y_train)\n",
    "dfTest4=X_test\n",
    "dfTest4['predictedSalary'] = L2Model.predict(X_test)\n",
    "dfTest4[\"actualSalary\"] = y_test\n",
    "print metrics.accuracy_score(y_test, dfTest4['predictedSalary'])\n",
    "print pd.crosstab(y_test, dfTest4['predictedSalary'], rownames=['Actual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3be94357-e551-4094-b784-2df039216d33"
   },
   "source": [
    "### BONUS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "#### Bonus: Use Count Vectorizer from scikit-learn to create features from the text summaries. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate the logistic regression model using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "fec80936-37bc-4922-89bd-b5d615566c9c"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "d42b9fd8-39d5-416a-b40b-7410e6396c11"
   },
   "source": [
    "#### Re-test L1 and L2 regularization. You can use LogisticRegressionCV to find the optimal reguarlization parameters. \n",
    "- Re-test what text features are most valuable.  \n",
    "- How do L1 and L2 change the coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "7570e237-c8cc-4e26-b569-7aee10627e79"
   },
   "source": [
    "Score: | 17/21\n",
    "------|-------\n",
    "Identify: Problem Statement / Aim| 1\n",
    "Acquire: Import Data Using Requests + BeautifulSoup| 3\n",
    "Parse: Clean & Organize Data| 3\n",
    "Model: Perform Logistic Regression| 3\n",
    "Evaluate: Logistic Regression\t\t\t\t|2\n",
    "Present: Write a report for your audience addressing findings & recommendations\t\t| 2\n",
    "Interactive visualization | 0\n",
    "Bonus: Countvectorizer, Regularization Parameters| 3\n",
    "Bonus! Present: Create blog post summary\t| 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#JB your code is great, but there is a serious lack of explanation\n",
    "# will make it very difficult for you to refine/improve this down the road."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
